// Package main is the entry point for the HumanMark API server.
//
// HumanMark is a simple API that verifies whether content (text, image, audio, video)
// was created by a human or generated by AI.
//
// Usage:
//
//	go run cmd/api/main.go
//
// Environment variables:
//
//	PORT              - Server port (default: 8080)
//	ENV               - Environment: development, staging, production (default: development)
//	DATABASE_URL      - PostgreSQL connection string
//	REDIS_URL         - Redis connection string
//	HIVE_API_KEY      - Hive AI API key for detection
//	LOG_LEVEL         - Logging level: debug, info, warn, error (default: info)
//	MAX_UPLOAD_SIZE   - Maximum upload size in bytes (default: 104857600 = 100MB)
package main

import (
	"context"
	"errors"
	"fmt"
	"net/http"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/humanmark/humanmark/internal/config"
	"github.com/humanmark/humanmark/internal/handler"
	"github.com/humanmark/humanmark/internal/middleware"
	"github.com/humanmark/humanmark/internal/repository"
	"github.com/humanmark/humanmark/internal/service"
	"github.com/humanmark/humanmark/pkg/logger"
)

// Version information - set at build time via ldflags
// Example: go build -ldflags "-X main.version=1.0.0" ./cmd/api
var (
	version   = "dev"
	buildTime = "unknown"
	gitCommit = "unknown"
)

func main() {
	// Initialize logger first - everything depends on logging
	log := logger.New(os.Getenv("LOG_LEVEL"))
	
	log.Info("starting humanmark api",
		"version", version,
		"build_time", buildTime,
		"git_commit", gitCommit,
	)

	// Load configuration from environment
	cfg, err := config.Load()
	if err != nil {
		log.Error("failed to load configuration", "error", err)
		os.Exit(1)
	}

	// Validate configuration
	if err := cfg.Validate(); err != nil {
		log.Error("invalid configuration", "error", err)
		os.Exit(1)
	}

	// Initialize dependencies
	// We use dependency injection for testability and flexibility
	app, err := initializeApp(cfg, log)
	if err != nil {
		log.Error("failed to initialize application", "error", err)
		os.Exit(1)
	}
	defer app.Cleanup()

	// Build the HTTP server with all middleware and routes
	server := buildServer(cfg, app, log)

	// Start server in a goroutine so we can handle graceful shutdown
	go func() {
		log.Info("server listening", "port", cfg.Port, "env", cfg.Environment)
		if err := server.ListenAndServe(); err != nil && !errors.Is(err, http.ErrServerClosed) {
			log.Error("server error", "error", err)
			os.Exit(1)
		}
	}()

	// Wait for interrupt signal for graceful shutdown
	// This allows in-flight requests to complete before shutting down
	gracefulShutdown(server, log, 30*time.Second)
}

// App holds all application dependencies.
// This struct makes it easy to pass dependencies around and clean up resources.
type App struct {
	Config     *config.Config
	Logger     *logger.Logger
	Repository repository.Repository
	Detector   service.Detector
	Handler    *handler.Handler
}

// Cleanup releases all resources held by the application.
// Always defer this after creating an App instance.
func (a *App) Cleanup() {
	a.Logger.Info("cleaning up resources")
	
	if a.Repository != nil {
		if err := a.Repository.Close(); err != nil {
			a.Logger.Error("error closing repository", "error", err)
		}
	}
}

// initializeApp creates and wires all application dependencies.
// This is the composition root where we decide which implementations to use.
func initializeApp(cfg *config.Config, log *logger.Logger) (*App, error) {
	// Initialize repository (database layer)
	// For now, we use an in-memory repository for simplicity
	// In production, swap this with PostgreSQL implementation
	repo, err := repository.NewPostgres(cfg.DatabaseURL)
	if err != nil {
		// Fall back to in-memory if no database configured
		log.Warn("database not configured, using in-memory storage")
		repo = repository.NewMemory()
	}

	// Initialize detection service
	// This orchestrates multiple detection backends
	detector, err := service.NewDetector(service.DetectorConfig{
		HiveAPIKey:    cfg.HiveAPIKey,
		OpenAIAPIKey:  cfg.OpenAIAPIKey,
		GPTZeroAPIKey: cfg.GPTZeroAPIKey,
		Timeout:       30 * time.Second,
	}, log)
	if err != nil {
		return nil, fmt.Errorf("failed to create detector: %w", err)
	}

	// Initialize HTTP handler
	h := handler.New(handler.Config{
		Detector:      detector,
		Repository:    repo,
		Logger:        log,
		MaxUploadSize: cfg.MaxUploadSize,
	})

	return &App{
		Config:     cfg,
		Logger:     log,
		Repository: repo,
		Detector:   detector,
		Handler:    h,
	}, nil
}

// buildServer creates the HTTP server with all routes and middleware.
// Middleware is applied in order: first listed = outermost (runs first on request, last on response)
func buildServer(cfg *config.Config, app *App, log *logger.Logger) *http.Server {
	// Create the main router
	mux := http.NewServeMux()

	// Register routes
	// Health check - no auth required
	mux.HandleFunc("GET /health", app.Handler.Health)
	mux.HandleFunc("GET /", app.Handler.Index)

	// Main API endpoint - the core of HumanMark
	// POST /verify - accepts URL or file upload, returns human/non-human verdict
	mux.HandleFunc("POST /verify", app.Handler.Verify)

	// Async job status (for large files)
	mux.HandleFunc("GET /verify/{id}", app.Handler.GetResult)

	// Apply middleware stack (order matters - first is outermost)
	var handler http.Handler = mux

	// Recovery middleware - catch panics, return 500 instead of crashing
	handler = middleware.Recovery(log)(handler)

	// Request ID middleware - add unique ID to each request for tracing
	handler = middleware.RequestID()(handler)

	// Logging middleware - log all requests with timing
	handler = middleware.Logging(log)(handler)

	// CORS middleware - allow cross-origin requests for browser clients
	handler = middleware.CORS(cfg.AllowedOrigins)(handler)

	// Rate limiting middleware - prevent abuse
	handler = middleware.RateLimit(cfg.RateLimitPerMinute)(handler)

	// Create server with sensible timeouts
	// These timeouts prevent slow clients from holding connections forever
	return &http.Server{
		Addr:              fmt.Sprintf(":%d", cfg.Port),
		Handler:           handler,
		ReadTimeout:       15 * time.Second,            // Max time to read request
		ReadHeaderTimeout: 5 * time.Second,             // Max time to read headers
		WriteTimeout:      60 * time.Second,            // Max time to write response (longer for file uploads)
		IdleTimeout:       120 * time.Second,           // Max time for keep-alive connections
		MaxHeaderBytes:    1 << 20,                     // 1 MB max header size
	}
}

// gracefulShutdown waits for interrupt signal and gracefully shuts down the server.
// It gives in-flight requests time to complete before forcing shutdown.
func gracefulShutdown(server *http.Server, log *logger.Logger, timeout time.Duration) {
	// Create channel to receive OS signals
	quit := make(chan os.Signal, 1)
	
	// Notify on SIGINT (Ctrl+C) and SIGTERM (docker stop, kill)
	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)

	// Block until we receive a signal
	sig := <-quit
	log.Info("received shutdown signal", "signal", sig.String())

	// Create context with timeout for shutdown
	ctx, cancel := context.WithTimeout(context.Background(), timeout)
	defer cancel()

	// Attempt graceful shutdown
	// This stops accepting new connections and waits for existing ones to finish
	log.Info("shutting down server", "timeout", timeout.String())
	if err := server.Shutdown(ctx); err != nil {
		log.Error("server forced to shutdown", "error", err)
	}

	log.Info("server stopped")
}
